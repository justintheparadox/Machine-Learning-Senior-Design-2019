{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-446a569efe4e>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-446a569efe4e>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    alexnet_output =\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "%run functions.ipynb\n",
    "\n",
    "def Alex_conv(imagenet_path, img_start, img_end, patch_no):\n",
    "    path = imagenet_path\n",
    "    test_images = sorted(os.listdir(path))\n",
    "    test = len(test_images)                                \n",
    "    x = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    y = Alexnet(x,1.0)\n",
    "    output = []\n",
    "    config = tf.ConfigProto(log_device_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    for i in range(img_start, img_end):\n",
    "        image_path = imagenet_path +\"//\"+ test_images[i]\n",
    "        image_patches = getpatches(image_path, patch_no)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        patches = sess.run(y,  feed_dict={x: image_patches})\n",
    "        output.append(patches)\n",
    "        \n",
    "def train_classifier(learning_rate, training_epochs, batch_size, total_images, alexnet_output, dropout, labels_path):\n",
    "    \n",
    "    no_batch = total_images/batch_size\n",
    "    labels = read_gt_label(labels_path)\n",
    "\n",
    "    x_batch = tf.placeholder(tf.float32, [None, 9216]) \n",
    "    y_batch = tf.placeholder(tf.float32, [None, 30])\n",
    "\n",
    "    intiailzer = tf.contrib.layers.xavier_initializer \n",
    "\n",
    "    W_1 = tf.get_variable(\"W_1\", [9216, 4096], intiailzer =initializer)\n",
    "    W_2 = tf.get_variable(\"W_2\", [9216, 4096], intiailzer =initializer)\n",
    "    W_3 = tf.get_variable(\"W_3\", [9216, 4096], intiailzer =initializer)\n",
    "    b_1 = tf.get_variable(\"b_1\", [9216, 4096])\n",
    "    b_2 = tf.get_variable(\"b_2\", [9216, 4096])\n",
    "    b_3 = tf.get_variable(\"b_3\", [9216, 4096])\n",
    "\n",
    "    fc1_z = tf.add(tf.matmul(x, W_1), b_1)\n",
    "    fc1_a = tf.nn.leaky_relu(fc1_z, 0.01)\n",
    "    fc1 = tf.nn.dropout(fc1_a, dropout)\n",
    "    fc2_z = tf.add(tf.matmul(fc2, W_1), b_2)\n",
    "    fc2_a = tf.nn.leaky_relu(fc1_z, 0.01)\n",
    "    fc2 = tf.nn.dropout(fc1_a, dropout)\n",
    "    fc3_z = tf.add(tf.matmul(fc2, W_1), b_2)\n",
    "    fc3_a = tf.nn.leaky_relu(fc3_z, 0.01)\n",
    "    fc3 = tf.nn.dropout(fc3_a, dropout)\n",
    "    out = tf.nn.softmax(fc3)\n",
    "\n",
    "    loss = loss_function(labels, out)\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, var_list = [W_1, W_2, W_3, b_1, b_2, b_3])\n",
    "\n",
    "    avg_loss=[ ]\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    count = 0\n",
    "    for epoch in training_epochs:\n",
    "        batch_cost=0\n",
    "        for batch in no_batch:\n",
    "            for image in alexnet_output[(batch*batch_size):((batch+1)*batch_size)]\n",
    "             _, cost = sess.run([optimiser, loss], feed_dict={x:image , y: labels[count]})\n",
    "                count+=1\n",
    "                batch_cost += cost\n",
    "            total_batch_cost += batch_cost\n",
    "        avg_batch_cost= total_batch_cost/no_batch\n",
    "        print(\"Cost is \", avg_batch_cost , \" for epoch \", epoch)\n",
    "        total_epoch_cost += avg_batch_cost\n",
    "    avg_epoch_cost = total_epoch_cost/training_epochs\n",
    "            \n",
    "       \n",
    "    sess.close()\n",
    "\n",
    "return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-ab8d8af9dd2c>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-ab8d8af9dd2c>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    alexnet_output =\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 1000)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "%run functions.ipynb\n",
    "%run AlexNet.ipynb\n",
    "\n",
    "def Alex_conv(imagenet_path, img_start, img_end, patch_no):\n",
    "    path = imagenet_path\n",
    "    test_images = sorted(os.listdir(path))\n",
    "    test = len(test_images)                                \n",
    "    x = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    y = Alexnet(x,1.0)\n",
    "    output = []\n",
    "    config = tf.ConfigProto(log_device_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    for i in range(img_start, img_end):\n",
    "        image_path = imagenet_path +\"//\"+ test_images[i]\n",
    "        image_patches = getpatches(image_path, patch_no)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        patches = sess.run(y,  feed_dict={x: image_patches})\n",
    "        output.append(patches)\n",
    "        \n",
    "    \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(learning_rate, training_epochs, batch_size, total_images, alexnet_output, dropout, labels_path):\n",
    "    \n",
    "    no_batch = total_images/batch_size\n",
    "    labels = read_gt_label(labels_path)\n",
    "\n",
    "    x_batch = tf.placeholder(tf.float32, [None, 9216]) \n",
    "    y_batch = tf.placeholder(tf.float32, [None, 30])\n",
    "\n",
    "    intiailzer = tf.contrib.layers.xavier_initializer \n",
    "\n",
    "    W_1 = tf.get_variable(\"W_1\", [9216, 4096], intiailzer =initializer)\n",
    "    W_2 = tf.get_variable(\"W_2\", [9216, 4096], intiailzer =initializer)\n",
    "    W_3 = tf.get_variable(\"W_3\", [9216, 4096], intiailzer =initializer)\n",
    "    b_1 = tf.get_variable(\"b_1\", [9216, 4096])\n",
    "    b_2 = tf.get_variable(\"b_2\", [9216, 4096])\n",
    "    b_3 = tf.get_variable(\"b_3\", [9216, 4096])\n",
    "\n",
    "    fc1_z = tf.add(tf.matmul(x, W_1), b_1)\n",
    "    fc1_a = tf.nn.leaky_relu(fc1_z, 0.01)\n",
    "    fc1 = tf.nn.dropout(fc1_a, dropout)\n",
    "    fc2_z = tf.add(tf.matmul(fc2, W_1), b_2)\n",
    "    fc2_a = tf.nn.leaky_relu(fc1_z, 0.01)\n",
    "    fc2 = tf.nn.dropout(fc1_a, dropout)\n",
    "    fc3_z = tf.add(tf.matmul(fc2, W_1), b_2)\n",
    "    fc3_a = tf.nn.leaky_relu(fc3_z, 0.01)\n",
    "    fc3 = tf.nn.dropout(fc3_a, dropout)\n",
    "    out = tf.nn.softmax(fc3)\n",
    "\n",
    "    loss = loss_function(labels, out)\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, var_list = [W_1, W_2, W_3, b_1, b_2, b_3])\n",
    "\n",
    "    avg_loss=[ ]\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    count = 0\n",
    "    for epoch in training_epochs:\n",
    "        batch_cost=0\n",
    "        for batch in no_batch:\n",
    "            for image in alexnet_output[(batch*batch_size):((batch+1)*batch_size)]\n",
    "             _, cost = sess.run([optimiser, loss], feed_dict={x:image , y: labels[count]})\n",
    "                count+=1\n",
    "                batch_cost += cost\n",
    "            total_batch_cost += batch_cost\n",
    "        avg_batch_cost= total_batch_cost/no_batch\n",
    "        print(\"Cost is \", avg_batch_cost , \" for epoch \", epoch)\n",
    "        total_epoch_cost += avg_batch_cost\n",
    "    avg_epoch_cost = total_epoch_cost/training_epochs\n",
    "            \n",
    "       \n",
    "sess.close()\n",
    "\n",
    "return\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
